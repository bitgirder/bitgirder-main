#!/usr/bin/env ruby

STDOUT.sync = true
STDERR.sync = true

require 'bitgirder/core'
require 'bitgirder/io'

require 'set'

module BitGirder
module Etl

class ExtractContext < BitGirder::Core::BitGirderClass
    bg_attr :id
    bg_attr :executor
end

class TransformSource < BitGirder::Core::BitGirderClass
    bg_attr :id
    bg_attr :coding
end

class TransformContext < BitGirder::Core::BitGirderClass
    bg_attr :id
    bg_attr identifier: :source, processor: TransformSource
    bg_attr :publish_to
    bg_attr :executor
end

class LoadContext < BitGirder::Core::BitGirderClass
    bg_attr :id
    bg_attr :load_from
    bg_attr :executor
end

class Pipeline < BitGirder::Core::BitGirderClass

    bg_attr :phases
    bg_attr identifier: :error_handler

    public
    def validate
        # STUB
    end

    %w{ extract transform load }.map { |w| w.to_sym }.each do |w|
        define_method( :"#{w}s" ) { @phases[ w ] }
    end
end

module InitMethods
    
    def opt_init( obj, *argv )
        if obj.respond_to?( :init )
            obj.send( :init, *argv )
        end
    end

    module_function :opt_init
end

class AppInit < BitGirder::Core::BitGirderClass
 
    bg_attr identifier: :conf
    bg_attr identifier: :error_handler

    private_class_method :new

    def self.get_instance
        @inst ||= self.send( :new ) 
    end

    private
    def impl_initialize
        @phases = {}
    end

    public
    def log( *argv )
        BitGirder::Core::BitGirderMethods.code( *argv )
    end

    {
        :extract => ExtractContext,
        :transform => TransformContext,
        :load => LoadContext,
    }.each_pair do |phase_id, cls|
        define_method( :"add_#{phase_id}" ) do |obj|
            obj = BitGirder::Core::BitGirderClass.as_instance( cls, obj )
            phase = ( @phases[ phase_id ] ||= {} )
            if phase.key?( id = obj.id )
                raise "Phase #{phase_id} already has an entry with id #{id}"
            else
                phase[ id ] = obj
            end
        end
    end

    public
    def error_handler=( eh )
        
        if eh.respond_to?( meth = :handle_error )
            @error_handler = eh
        else
            raise "Error handler does not respond to #{meth.inspect}: #{eh}"
        end
    end

    private
    def build_pipeline

        Pipeline.new( 
            phases: @phases,
            error_handler: @error_handler,
        )
    end
end

class EtFlowGroup < BitGirder::Core::BitGirderClass

    bg_attr :transform_ids
    bg_attr identifier: :next_read, mutable: true
    bg_attr identifier: :active, default: true, mutable: true
end

class EtFlow < BitGirder::Core::BitGirderClass

    bg_attr :ex_ctx
    bg_attr identifier: :groups, default: proc { [] } 
    bg_attr identifier: :transform_ids, default: proc { [] }

    public
    def active?
        @groups.find { |grp| grp.active }
    end
end

class Publisher < BitGirder::Core::BitGirderClass
    
    bg_attr :ld_ctx

    private
    def impl_initialize
        @recs = []
    end

    public
    def init
        InitMethods.opt_init( @ld_ctx.executor )
    end

    public
    def publish( rec )
        @recs << rec
    end

    public
    def update
        
        unless @recs.empty?
            
            code( "Calling publisher #{@ld_ctx.id} with #{@recs.size} recs" )
            @ld_ctx.executor.execute( @recs )
            @recs.clear
        end
    end
end

class RecordException < BitGirder::Core::BitGirderClass
    bg_attr :exception
    bg_attr :block
    bg_attr :id
    bg_attr :record
    bg_attr :coding
    bg_attr :phase
end

class TransformCall < BitGirder::Core::BitGirderClass
 
    bg_attr :block
    bg_attr :pub
    bg_attr :exec_id
    bg_attr :error_handler
    bg_attr :source

    public
    def publish( rec )
        @pub.publish( rec )
    end

    public
    def each_coding_with_id( coding )

        @block.coding( coding ).each_with_id do |rec, id|
            begin
                yield( rec, id )
            rescue Exception => e
                @error_handler.handle_error( 
                    RecordException.new(
                        exception: e,
                        block: @block,
                        id: id,
                        record: rec,
                        coding: coding,
                        phase: PHASE_TRANSFORM,
                        executor_id: @exec_id,
                    )
                )
            end
        end
    end

    public
    def each_coding( coding )
        each_coding_with_id( coding ) { |rec, id| yield( rec ) }
    end
end

class EtlDaemonState < BitGirder::Core::BitGirderClass
    
    bg_attr identifier: :transforms, default: proc { {} }
end

class Runtime < BitGirder::Core::BitGirderClass
 
    bg_attr :et_flows
    bg_attr :transforms
    bg_attr :loads
    bg_attr :daemon
    bg_attr identifier: :error_handler

    include BitGirder::Io

    private
    def impl_initialize
        @publishers = {}
    end

    private
    def state_file
        "#{@daemon.run_dir}/etl-state.yaml"
    end

    private
    def codings_for_et_flow( etf )
 
        etf.transform_ids.inject( Set.new ) do |s, id|
            s << transforms[ id ].source.coding
        end.to_a
    end

    private
    def codings_for_group( grp )

        grp.transform_ids.inject( Set.new ) do |s, id|
            s << transforms[ id ].source.coding
        end.to_a
    end

    private
    def publisher_for( tr_id )
        tr_ctx = transforms[ tr_id ]
        @publishers[ tr_ctx.publish_to ]
    end

    private
    def error_handler_for( obj )
        
        res = obj.respond_to?( :error_handler ) ? obj.error_handler : nil

        res ||= @error_handler

        unless res
            res = Object.new
            class <<res
                def handle_error( err ) 
                    raise err
                end
            end
        end

        res
    end

    private
    def read_state
        
        if File.exists?( f = state_file )
            load_yaml( f )
        else
            nil
        end
    end

    private
    def init_et_flow_groups( etf, d_state )
        
        # nil will be a valid key for transforms with no saved state
        groups = {}

        reads = ( d_state && d_state.transforms ) || {}

        etf.transform_ids.each do |id|
            ( groups[ reads[ id ] ] ||= [] ) << id
        end

        groups.each_pair do |next_read, ids|
            etf.groups << EtFlowGroup.new( 
                next_read: next_read, 
                transform_ids: ids
            )
        end
    end

    private
    def init_et_flows( d_state )

        @et_flows.values.each do |etf|
            code( "Initializing extractor #{etf.ex_ctx.id}" )
            init_argv = { codings: codings_for_et_flow( etf ) }
            InitMethods.opt_init( etf.ex_ctx.executor, init_argv )
            init_et_flow_groups( etf, d_state )
        end
    end

    private
    def init_publishers
 
        pub_ids = Set.new

        @transforms.values.each do |tr_ctx|
            if @loads.key?( pub_id = tr_ctx.publish_to )
                pub_ids << pub_id
            else
                raise "Transform #{tr_ctx.id} publishes to #{pub_id}, " \
                      "which has no associated loader"
            end
        end

        pub_ids.each do |id|
            pub = ( @publishers[ id ] = Publisher.new( ld_ctx: @loads[ id ] ) )
            InitMethods.opt_init( pub )
        end
    end

    private
    def init

        d_state = read_state
        init_et_flows( d_state )
        init_publishers
    end

    private
    def process_block( grp, block )
 
        grp.transform_ids.each do |tr_id|

            tr_ctx = @transforms[ tr_id ]

            tc = TransformCall.new( 
                block: block, 
                pub: publisher_for( tr_id ),
                exec_id: tr_id,
                error_handler: error_handler_for( tr_ctx ),
                source: tr_ctx.source,
            )
            
            code( "Sending block of #{block.size} to transform #{tr_id}" )
            tr_ctx.executor.execute( tc )
        end
    end

    private
    def run_et_flows
 
        @et_flows.values.each do |etf|
            etf.groups.each do |grp|
                code( 
                    "Running et flow group with ids #{grp.transform_ids}, " \
                    "next read: #{grp.next_read.inspect}" )
                opts = {
                    max_results: @daemon.batch_size, 
                    codings: codings_for_group( grp ),
                    next_read: grp.next_read,
                }
                if block = etf.ex_ctx.executor.read_block( opts )
                    process_block( grp, block ) 
                    grp.next_read = block.next_read
                    grp.active = true
                else
                    grp.active = false
                end
            end
        end
    end

    private
    def run_loads

        @publishers.values.each do |pub| 
            pub.update 
        end
    end

    private
    def get_transform_state
        
        @et_flows.values.inject( {} ) do |h, etf|
            etf.groups.each do |grp|
                grp.transform_ids.each { |id| h[ id ] = grp.next_read }
            end
            h
        end
    end

    private
    def get_state_object
        
        EtlDaemonState.new(
            transforms: get_transform_state,
        )
    end

    private
    def write_state
        
        obj = get_state_object
        dump_yaml( obj, state_file )
    end

    private
    def run_once

        run_et_flows
        run_loads
        write_state
    end

    private
    def run_loop

        while true
            run_once
            unless has_active_flow?
                code( "No flows active, sleeping #{@daemon.poll_at}" )
                sleep @daemon.poll_at
            end
        end
    end

    private
    def has_active_flow?
        @et_flows.values.find { |etf| etf.active? }
    end

    public
    def run

        init
        run_loop
    end
end

class EtlDaemon < BitGirder::Core::BitGirderClass

    bg_attr identifier: :ruby_include, is_list: true, validation: :file_exists

    bg_attr identifier: :etl_init, validation: :file_exists

    bg_attr identifier: :etl_conf,
            validation: :opt_file_exists
    
    bg_attr identifier: :run_dir, validation: :file_exists

    bg_attr identifier: :batch_size, validation: :positive, default: 1000
    
    bg_attr identifier: :poll_at, 
            validation: :positive, 
            processor: :integer,
            default: 60

    private
    def load_etl_conf
        BitGirder::Io.load_yaml( @etl_conf )
    end

    private
    def init_etl

        ai = AppInit.get_instance
        ai.instance_variable_set( :@conf, load_etl_conf ) if @etl_conf

        load @etl_init, false

        AppInit.get_instance.send( :build_pipeline )
    end
 
    private
    def build_et_flows( pl )

        transforms = {}.merge( pl.transforms || {} )
        flows = {}

        pl.extracts.values.each do |ex_ctx|
            etf = flows[ ex_id = ex_ctx.id ] = EtFlow.new( ex_ctx: ex_ctx )
            transforms.reject! do |tr_id, tr_ctx|
                tr_ctx.source.id == ex_id && etf.transform_ids << tr_id
            end 
        end

        transforms.empty? or raise "Unmatched transforms: #{transforms.keys}"

        flows
    end

    private
    def build_runtime( pl )
        Runtime.new( 
            et_flows: build_et_flows( pl ),
            transforms: {}.merge( pl.transforms || {} ),
            loads: {}.merge( pl.loads ),
            error_handler: pl.error_handler,
            daemon: self,
        )
    end

    public
    def run( run_ctx )
        $:.push( *@ruby_include )
        pl = init_etl 
        rt = build_runtime( pl )
        rt.run
    end

end

end
end

BitGirder::Core::BitGirderCliApplication.run( BitGirder::Etl::EtlDaemon )
